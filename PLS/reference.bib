@article{JSSv018i02,
 title={The pls Package: Principal Component and Partial Least Squares Regression in R},
 volume={18},
 url={https://www.jstatsoft.org/index.php/jss/article/view/v018i02},
 doi={10.18637/jss.v018.i02},
 abstract={The pls package implements principal component regression (PCR) and partial least squares regression (PLSR) in R (R Development Core Team 2006b), and is freely available from the Comprehensive R Archive Network (CRAN), licensed under the GNU General Public License (GPL). The user interface is modelled after the traditional formula interface, as exemplified by lm. This was done so that people used to R would not have to learn yet another interface, and also because we believe the formula interface is a good way of working interactively with models. It thus has methods for generic functions like predict, update and coef. It also has more specialised functions like scores, loadings and RMSEP, and a exible crossvalidation system. Visual inspection and assessment is important in chemometrics, and the pls package has a number of plot functions for plotting scores, loadings, predictions, coefficients and RMSEP estimates. The package implements PCR and several algorithms for PLSR. The design is modular, so that it should be easy to use the underlying algorithms in other functions. It is our hope that the package will serve well both for interactive data analysis and as a building block for other functions or packages using PLSR or PCR. We will here describe the package and how it is used for data analysis, as well as how it can be used as a part of other packages. Also included is a section about formulas and data frames, for people not used to the R modelling idioms.},
 number={2},
 journal={Journal of Statistical Software},
 author={Mevik, Björn-Helge and Wehrens, Ron},
 year={2007},
 pages={1–23}
}

@article{GELADI19861,
title = {Partial least-squares regression: a tutorial},
journal = {Analytica Chimica Acta},
volume = {185},
pages = {1-17},
year = {1986},
issn = {0003-2670},
doi = {https://doi.org/10.1016/0003-2670(86)80028-9},
url = {https://www.sciencedirect.com/science/article/pii/0003267086800289},
author = {Paul Geladi and Bruce R. Kowalski},
abstract = {A tutorial on the partial least-squares (PLS) regression method is provided. Weak points in some other regression methods are outlined and PLS is developed as a remedy for those weaknesses. An algorithm for a predictive PLS and some practical hints for its use are given.}
}

@article{DEJONG1993251,
title = {SIMPLS: An alternative approach to partial least squares regression},
journal = {Chemometrics and Intelligent Laboratory Systems},
volume = {18},
number = {3},
pages = {251-263},
year = {1993},
issn = {0169-7439},
doi = {https://doi.org/10.1016/0169-7439(93)85002-X},
url = {https://www.sciencedirect.com/science/article/pii/016974399385002X},
author = {Sijmen {de Jong}},
abstract = {De Jong, S., 1993. SIMPLS: an alternative approach to partial least squares regression. Chemometrics and Intelligent Laboratory Systems, 18: 251–263. A novel algorithm for partial least squares (PLS) regression, SIMPLS, is proposed which calculates the PLS factors directly as linear combinations of the original variables. The PLS factors are determined such as to maximize a covariance criterion, while obeying certain orthogonality and normalization restrictions. This approach follows that of other traditional multivariate methods. The construction of deflated data matrices as in the nonlinear iterative partial least squares (NIPALS)-PLS algorithm is avoided. For univariate y SIMPLS is equivalent to PLS1 and closely related to existing bidiagonalization algorithms. This follows from an analysis of PLS1 regression in terms of Krylov sequences. For multivariate Y there is a slight difference between the SIMPLS approach and NIPALS-PLS2. In practice the SIMPLS algorithm appears to be fast and easy to interpret as it does not involve a breakdown of the data sets.}
}